---
title: "Creating a Social Vulnerability Index with ACS Data"
author: "Patrick Bixler and Ethan Tenison"
date: "`r format(Sys.Date(), '%B %d, %Y') `"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

#library(devtools) #use dev version to see geographies 
#install_github("walkerke/tidycensus")

library(tidyverse) #ploting, data cleaning
library(tidycensus) #Census api 
library(psych) #Factor Analysis
library(caret) #Preposing Algorithms
library(tigris)
library(leafem)
library(mapview)
```


# Constructing the Social Vulnerability index

For reference, the following (Medium Post)[https://medium.com/analytics-vidhya/the-factor-analysis-for-constructing-a-composite-index-2496686fc54c] was used to guide the svi's consturction. While it was conducted in Python using a variety of packages, I was able to recreate it in R using primarily the `psych` and `caret` packages which are used extensively in statistics. 

# ACS Variables

In order to construct the Social Vulnerability Index, 18 variables were pulled from the 2020 ACS 5-year estimates using the `tidycensus` package. The variables are as follows:

* Wealth
  + QRICH = Percent Households Earning over $200,000 annually
  + MDHSEVAL = Median Housing Value
  + PERCAP = Per Capita Income
  + MDGRENT = Median Gross Rent
* Language & Education 
  + QESL = Percent Speaking English as a Second Language with Limited Proficiency
  + QSPANISH =  Percent Hispanic 
  + QED12LES = Percent Less than high school education for population over 25 years and older
* Elderly
  + QSSBEN = Percent Households Receiving Social Security Benefits
  + QAGEDEP = Percent Population under 5 years or 65 and over
  + MEDAGE = Median age 
* Housing Status 
  + PPUNIT = People per Unit (Average household size)
  + QFAM = Percent Children Living with both parents 
* Social Status
  + QCVLUN = Percent Unemployment for Civilian in Labor Force 16 Years and Over
  + QBLACK = Percent Black or African American Alone
  + QNOAUTO = Percent Housing Units with No Car
  + QPOVTY = Percent Poverty
* Gender
  + QFEMALE = Percent Female 
  + QFEMLBR = Percent Female Participation in Labor Force
  
  
```{r v_search, eval=FALSE, include=FALSE}

v20 <- load_variables(2020, "acs5")

```

# `Tidycensus`

All the data was pulled for the state of Texas. The results data frame is in long format and must be pivoted wider for analysis. You can find documentation about the package on the [Tidycensus](https://walker-data.com/tidycensus/) website.


```{r tidycensus}

#acs variables 
vars <- c(	
"QRICH" = "B19001_017", #need to divide households 
"households" = "B09019_002",
"MDGRENT" = "B25064_001",
"MDHSEVAL" = 	"B25077_001",
"PERCAP" = "B19301_001",
"QESL-Spanish" = "B06007_005", #need to be added together and divided by pop 
"QESL-Other" = "B06007_008",
"QSPANISH" = "B03001_003", # need to divide by pop
"POP" = "B03001_001",
"QED12LES" = "B16010_002", # divide by pop
"QSSBEN" = "B19055_002", #divide by pop 
"QAGEDEP-under5" = "B06001_002",#add together and divide by pop
"QAGEDEP-over65" = "B18135_024",
"MEDAGE"= "B07002_001",
"PPUNIT" = "B25010_001",
"QFAM_under6" = "B05009_003", #add together and divide by children
"QFAM_to17" = "B05009_021",
"children" = "B05009_001",
"QCVLUN" = "B23025_005", # divide by pop 
"QBLACK" = "B18101B_001", #divide by pop,
"QNOAUTO" = "B08203_002", #divide by households 
"QPOVTY" = "B17020_002", #divide by pop
"QFEMALE" = "B01001_026", # divide by pop
"wlab1" = "C23002A_004", #can't really pull female labor participation except by race
"wlab2" = "C23002B_004", #Then divide by over 16
"wlab3" = "C23002C_004",
"wlab4" = "C23002D_004",
"wlab5" = "C23002E_004",
"wlab6" = "C23002F_004",
"wlab7" = "C23002G_004",
"f1" = "B01001_030", #pulling pop by age is actually the worst!
"f2" = "B01001_031",
"f3" = "B01001_032",
"f4" = "B01001_033",
"f5" = "B01001_034",
"f6" = "B01001_035",
"f7" = "B01001_036",
"f8" = "B01001_037",
"f9" = "B01001_038",
"f10" = "B01001_039",
"f11" = "B01001_040",
"f12" = "B01001_041",
"f13" = "B01001_042",
"f14" = "B01001_043",
"female_over65" = "B15001_076" 
)

#counties <- c("Travis", "Bastrop","Blanco", "Burnet", "Caldwell",
  #            "Fayette", "Hays", "Lee", "Llano", "Williamson")

#census_api_key("cbef6ecf15f8b2c9e1cb135b09f5bee3ead9c5a1", install=TRUE)
acs <-get_acs(state="TX", geography="tract",year = 2020,
              variables=vars, geometry= F) 

df_raw <- acs |> 
  select(GEOID, variable, estimate) |> 
  pivot_wider(id_cols = GEOID, 
              names_from = variable,
              values_from = estimate) 

```

# Data cleaning

Many of the variables total estimates, and need to be divided by the population. Additionally, some variables have much narrower populations, such as women in the labor force, and require more variables to construct the numerator. `NA` values and infinite values also have to be removed from the resulting data frame. In most cases `NA` were substituted with 0, but infinite values were removed completely.

```{r dc}

df <- df_raw |>
  mutate(
    QRICH = QRICH / households,
    QESL = (`QESL-Spanish` + `QESL-Other`) / POP,
    QSPANISH = QSPANISH / POP,
    QED12LES = QED12LES / POP,
    QSSBEN = QSSBEN / POP,
    QAGEDEP = (`QAGEDEP-under5` + `QAGEDEP-over65`) / POP,
    QFAM = (QFAM_under6 + QFAM_to17) / children,
    QCVLUN = QCVLUN / POP,
    QBLACK = QBLACK / POP,
    QNOAUTO = QNOAUTO / households,
    QPOVTY = QPOVTY / POP,
    QFEMALE = QFEMALE / POP,
    QFEMLBR = (wlab1 + wlab2 + wlab3 + wlab4 + wlab5 + wlab6 + wlab7) /
      (
        f1 + f2 + f3 + f4 + f5 + f6 + f7 + f8 + f9 + f10 + f11 + f12 + f13 + f14 + female_over65
      )
  ) |>
  select(
    -c(
      #Variables to remove
      POP,
      children,
      QFAM_under6,
      QFAM_to17,
      households,
      female_over65,
      `QAGEDEP-under5`,
      `QAGEDEP-over65`,
      `QESL-Spanish`,
      `QESL-Other`,
      starts_with("wlab"),
      "f1","f2","f3" ,"f4","f5" ,"f6" ,"f7" ,"f8" ,"f9" ,"f10" ,"f11" ,"f12","f13" ,
      "f14" ,
    )
  ) |> 
  mutate(across(2:19,~replace_na(.x,0))) |> 
  filter(across(everything(), ~!is.infinite(.)))

head(df)

```


# Minmax scaling 

Because each variable is in different units, it was important to transform the data to the same scale. Min-max scaling was used to convert the units from 0-1 using the `caret` function `preProcess`. 


```{r scaling}


minmax <- preProcess(df[,-1], method = "range")

transformed <- predict(minmax, df[,-1])

```


# Factor Analysis  

With the transformed data, a factor analysis with varimax rotation was performed to reduce dimensionality. According to the Kaiser criterion, there were 5 relevant factors, where eigenvalues are greater than 1.You can view these results in the following scree plot. 

```{r factors}

my_fa <-
  fa(
    r = transformed,
    nfactors = 18,
    rotate = "varimax",
    fm = "minres"
  )

print(my_fa$e.values)

e <- as.data.frame(my_fa$e.values) |> 
  rename(e_values = `my_fa$e.values`) |> 
  rownames_to_column("Factor") 

e$Factor <- factor(e$Factor, levels = unique(e$Factor))

theme_set(theme_classic())
scree_plot <- ggplot(data = e, aes(x = Factor , y = e_values, group = 1)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  geom_hline(yintercept = 1, linetype='dashed', col = 'red', size = 1) +
  labs(
    title = "Scree plot of eigen values from factor analysis",
    y = "Eigenvalue",
    x = "Factors",
    caption = "*Eigenvalues > 1 means that the factor contains more information than one variable"
  )

scree_plot

```

# Factor Analysis Results 

Determining the dominant indicators in a factor is based on the their loading scores. A loading score of > 0.5 signifies importance. Still, each factor includes all indicators to some degree, unless the loading score is 0. Please note that the factors were created using the minimum residual method, and as such each factor column is labeled MR. After computing each factor, they were reordered based on variance explained. 

Most important variables in each factor:
* **Factor 1**: QRICH, PERCAP, MDHSEVAL
* **Factor 2**: QSPANISH, QED12LES, QESL
* **Factor 3**: MEDAGE, QSSBEN, QAGEDEP
* **Factor 4**: QNOAUTO, QPOVTY(at .45)
* **Factor 5**: QFEMALE

Additionally, from the summary table below we can see that the first 5 factors account for approximately 72% of variance explained. Generally speaking, > 60% explained variance is considered a good factor analysis.

```{r}

print(my_fa)

```

# Computing SVI

The factor scores are based on their z-scores, making comparison difficult. For that reason, minmax-scaling was used again to convert the scale from 0-1.Then, the direction of the components were adjusted to correspond theoretically to higher social vulnerability. Since component one has to do with wealth, where lower values increase vulnerability, the direction is changed to negative. Finally, all the scores are summed together to get the final numerical composite score. 


```{r factor_scores}

#NOTE factor numbers will change based on subsequent years! Change accordingly
scores <- as.data.frame(my_fa$scores) |> 
  select(MR1, MR10, MR2, MR4, MR5)


minmax <- preProcess(scores, method = "range")

trans_scores <- predict(minmax, scores)

svi <- trans_scores |> 
  mutate(MR1 = MR1*-1,
    SVI = MR1 + MR10 + MR2 + MR4 + MR5) |> 
  select(SVI)

minmax <- preProcess(svi, method = "range")

svi <- predict(minmax, svi)


```


# Plotting

```{r plotting}


#enter your key census_api_key("Your key here")
acs2 <-get_acs(state="TX", geography="tract",year = 2020,
              variables="B03001_001", geometry= T) 

tracts <- acs2 |> 
  distinct(GEOID, .keep_all = TRUE) |> 
  select(GEOID, geometry)

df2 <- df |> 
  bind_cols(svi)

library(leaflet)
library(sf)
df2 <- df2 |> 
  right_join(tracts, by = "GEOID") |> 
  st_as_sf() |> 
  filter(!is.na(GEOID)) #|> 
  #mutate(index = scale(index))

df2 <- na.omit(df2)
  
plot(df2["SVI"])

df2 <- as.data.frame(df2) |> 
  select(GEOID, SVI)

write.csv(df2, "data/processed/svi_tracts.csv")


```
# SVI at Major Metro Counties

```{r travis county}
austin_tracts <- tracts("TX", "Travis")
plot(austin_tracts$geometry)

df2 <- df2 |> 
  right_join(tracts, by = "GEOID") |> 
  st_as_sf() |> 
  filter(!is.na(GEOID)) #|> 

#travis_svi <- st_join(austin_tracts, df2)

```



# Census Block Groups

The following code was used to compute the SVI scores for census block groups. Although it is virtually identical, female labor force participation was not available and had to be taken out. The most important indicators also changed slightly from the census tracts. 


```{r cbg, message = FALSE, warning = FALSE}


#acs variables 
vars <- c(	
"QRICH" = "B19001_017", #need to divide households 
"households" = "B09019_002",
"MDHSEVAL" = 	"B25077_001",
"MDGRENT" = "B25064_001",
"PERCAP" = "B19301_001",
"QESL-Spanish" = "C16002_004", #need to be added together and divided by household
"QESL-Other" = "C16002_013",
"QSPANISH" = "B03002_012", # need to divide by pop
"POP" = "B01003_001",
"QED12LES" = "B28006_002", # divide by pop
"QSSBEN" = "B19055_002", #divide by pop 
"QAGEDEP-under5-male" = "B01001_003",#add together and divide by pop
"QAGEDEP-under5-female" = "B01001_027",
"QAGEDEP-over65" = "B09021_022",
"MEDAGE"= "B01002_001",
"PPUNIT" = "B25010_001",
"QFAM" = "B09002_002", #divide by children
"children" = "B09002_001",
"QCVLUN" = "B23025_005", # divide by pop 
"QBLACK" = "B02009_001", #divide by pop,
"QNOAUTO-owner" = "B25044_003", #add and divide by households 
"QNOAUTO-renter" = "B25044_010",
"QPOVTY" = "B17021_002", #divide by pop
"QFEMALE" = "B01001_026"#, # divide by pop
# "wlab1" = #"C23002A_004", #add together COULD NOT FIND 
# "wlab2" = #"C23002B_004", #Then divide by over 16
# "wlab3" = #"C23002C_004",
# "wlab4" = #"C23002D_004",
# "wlab5" = #"C23002E_004",
# "wlab6" = #"C23002F_004",
# "wlab7" = #"C23002G_004",
# "f1" = "B01001_030", #pulling pop by age is actually the worst!
# "f2" = "B01001_031",
# "f3" = "B01001_032",
# "f4" = "B01001_033",
# "f5" = "B01001_034",
# "f6" = "B01001_035",
# "f7" = "B01001_036",
# "f8" = "B01001_037",
# "f9" = "B01001_038",
# "f10" = "B01001_039",
# "f11" = "B01001_040",
# "f12" = "B01001_041",
# "f13" = "B01001_042",
# "f14" = "B01001_043",
# "female_over65" = "B15011_034" 
)

counties <- c("Travis", "Bastrop","Blanco", "Burnet", "Caldwell",
              "Fayette", "Hays", "Lee", "Llano", "Williamson")

#enter your key census_api_key("Your key here")
acs_cbg <-get_acs(state="TX", geography="block group",year = 2020,
              variables=vars, geometry= F) 

cbg_raw <- acs_cbg |> 
  select(GEOID, variable, estimate) |> 
  pivot_wider(id_cols = GEOID, 
              names_from = variable,
              values_from = estimate) 


```

```{r cbg_cleaning}


cbg <- cbg_raw |>
  mutate(
    QRICH = QRICH / households,
    QESL = (`QESL-Spanish` + `QESL-Other`) / POP,
    QSPANISH = QSPANISH / POP,
    QED12LES = QED12LES / POP,
    QSSBEN = QSSBEN / POP,
    QAGEDEP = (`QAGEDEP-under5-male` + `QAGEDEP-under5-female` +
                 `QAGEDEP-over65`) / POP,
    QFAM = (QFAM) / children,
    QCVLUN = QCVLUN / POP,
    QBLACK = QBLACK / POP,
    QNOAUTO = (`QNOAUTO-owner` + `QNOAUTO-renter`) / households,
    QPOVTY = QPOVTY / POP,
    QFEMALE = QFEMALE / POP
  ) |>
  select(
    -c(
      #Variables to remove
      POP,
      children,
      households,
      `QAGEDEP-under5-male`,
      `QAGEDEP-under5-female`,
      `QAGEDEP-over65`,
      `QESL-Spanish`,
      `QESL-Other`,
      `QNOAUTO-owner`,
      `QNOAUTO-renter`
  )) |> 
  mutate(across(2:18,~replace_na(.x,0))) |> 
  filter(across(everything(), ~!is.infinite(.)))

head(cbg)

```

```{r fa_cbg}
minmax <- preProcess(cbg[,-1], method = "range")

transformed <- predict(minmax, cbg[,-1])



my_fa <-
  fa(
    r = transformed,
    nfactors = 17,
    rotate = "varimax",
    fm = "minres"
  )

print(my_fa$e.values)

e <- as.data.frame(my_fa$e.values) |> 
  rename(e_values = `my_fa$e.values`) |> 
  rownames_to_column("Factor") 

e$Factor <- factor(e$Factor, levels = unique(e$Factor))

theme_set(theme_classic())
scree_plot <- ggplot(data = e, aes(x = Factor , y = e_values, group = 1)) +
  geom_line(size = 1) +
  geom_point(size = 1) +
  geom_hline(yintercept = 1, linetype='dashed', col = 'red', size = 1) +
  labs(
    title = "Scree plot of eigen values from factor analysis",
    y = "Eigenvalue",
    x = "Factors",
    caption = "*Eigenvalues > 1 means that the factor contains more information than one variable"
  )

scree_plot

```
Most important variables in each factor (for cbg):
* **Factor 1**: QRICH, PERCAP, MDHSEVAL
* **Factor 2**: MEDAGE, QSSBEN, QAGEDEP
* **Factor 3**: QSPANISH, QED12LES, QESL
* **Factor 4**: PPUNIT
* **Factor 5**: QFAM

```{r cbg_fa_summary}

print(my_fa)

```
```{r svi_cbg}


scores <- as.data.frame(my_fa$scores) |> 
  select(MR1, MR2, MR4, MR11, MR8)


minmax <- preProcess(scores, method = "range")

trans_scores <- predict(minmax, scores)

svi <- trans_scores |> 
  mutate(MR1 = MR1*-1,
         SVI = MR1 + MR2 + MR4 + MR11 + MR8) |> 
  select(SVI)

minmax <- preProcess(svi, method = "range")

svi <- predict(minmax, svi)

```


```{r cgb_geo, message=FALSE, warning=FALSE, include=FALSE}
counties <- c("Travis", "Bastrop","Blanco", "Burnet", "Caldwell",
              "Fayette", "Hays", "Lee", "Llano", "Williamson")

#enter your key census_api_key("Your key here")
acs2 <-get_acs(state="TX", geography="block group",year = 2020,
              variables="B03001_001", geometry= T) 


```



```{r cbg_plotting}

block_group <- acs2 |> 
  distinct(GEOID, .keep_all = TRUE) |> 
  select(GEOID, geometry)

df2 <- cbg |> 
  bind_cols(svi)

library(leaflet)
library(sf)
df2 <- df2 |> 
  right_join(block_group, by = "GEOID") |> 
  st_as_sf() |> 
  filter(!is.na(GEOID)) 

df2 <- na.omit(df2)
  
plot(df2["SVI"])

df2 <- as.data.frame(df2) |> 
  select(GEOID, SVI)

write.csv(df2, "data/processed/svi_cbg.csv")
```

